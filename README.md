# BIG_DATA_LAB2

# Анализ задержек авиарейсов с использованием Spark и Hadoop

Этот проект демонстрирует обработку больших данных о задержках авиарейсов с использованием Apache Spark и Hadoop HDFS. Проект включает сравнение производительности базовой и оптимизированной версий приложения на кластерах с разным количеством узлов.

## Описание задания

1. Использован датасет со 150,000 строками и 6+ признаками (включая категориальные)
2. Развернут Hadoop (1 NameNode + 1/3 DataNode) с ограничением памяти
3. Реализовано Spark-приложение с замерами времени и памяти
4. Проведено сравнение производительности для 4 конфигураций:
   - 1 DataNode (базовая версия)
   - 1 DataNode (оптимизированная версия)
   - 3 DataNode (базовая версия)
   - 3 DataNode (оптимизированная версия)
5. Применены оптимизации: кэширование (`cache()`), репартиционирование (`repartition()`)

## Структура проекта
```
project-root/
├── app_spark.py # Основное Spark-приложение (анализ + ML)
├── docker-compose.yml # Конфигурация кластера (Hadoop+Spark)
├── hadoop.env # Настройки Hadoop
├── run.sh # Скрипт запуска
└── 2018_small.csv # Пример датасета (150000 строк)
```

## Инструкция по запуску

### Предварительные требования
- Docker и Docker Compose установлены
- Файл с данными `2018_small.csv` в корне проекта

### Запуск кластера (1 DataNode)
```bash
# Развертывание кластера
docker-compose-1dn up -d
# Запуск Spark app
./run.sh
```

### Запуск кластера (3 DataNode)
```bash
# Развертывание кластера
docker-compose-3dn up -d
# Запуск Spark app
./run.sh
```

## Производительность

### Сравнение времени выполнения и использования памяти

| Конфигурация       | Время (сек) | Память (MB) |
|--------------------|-------------|-------------|
| **1 DataNode**     |             |             |
| Базовый вариант    | 29.84       | 38.11       |
| Оптимизированный   | 31.79       | 38.23       |
| **3 DataNode**     |             |             |
| Базовый вариант    | 32.57       | 38.07       |
| Оптимизированный   | 27.86       | 37.87       |

**Ключевые выводы:**
- Оптимизированная версия на 3 узлах показала наилучшее время выполнения (27.86 сек)
- Использование памяти оставалось стабильным (~38 MB) во всех тестах
- Распределение на 3 узла дало прирост только с оптимизациями




